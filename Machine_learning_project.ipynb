{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2VaNoxnxUTb"
      },
      "source": [
        "## Importing main libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NYZT2c0IxUTc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report,mean_squared_error\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from tkinter import Tk, Button, filedialog, Text, Listbox, Scrollbar, Toplevel, Label, Entry,LEFT\n",
        "import threading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNEoMX1exUTd"
      },
      "source": [
        "## Browse the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WlqV-pB7xUTd"
      },
      "outputs": [],
      "source": [
        "df = None\n",
        "target_column = None\n",
        "target_column_regression = None\n",
        "num_clusters = None\n",
        "percent = None\n",
        "def browse_file():\n",
        "    global df\n",
        "    filename = filedialog.askopenfilename(filetypes=[(\"CSV files\", \"*.csv\"), (\"All files\", \"*.*\")])\n",
        "    if filename:\n",
        "        try:\n",
        "            df = pd.read_csv(filename)\n",
        "            display_data(\"Data loaded successfully.\")\n",
        "        except Exception as e:\n",
        "            display_data(\"Error loading data: \" + str(e))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HDNL4CPxUTe"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6XlOx-7NxUTe"
      },
      "outputs": [],
      "source": [
        "def head_of_data():\n",
        "    return df.head()\n",
        "\n",
        "def tail_of_data():\n",
        "    return df.tail()\n",
        "\n",
        "def info_about_data():\n",
        "    return str(df.info)\n",
        "\n",
        "def describe_data():\n",
        "    return str(df.describe())\n",
        "\n",
        "def shape_of_data():\n",
        "    return df.shape\n",
        "\n",
        "def columns_of_data():\n",
        "    return df.columns.tolist()\n",
        "\n",
        "def nans_in_data():\n",
        "    return df.isna().sum()\n",
        "\n",
        "def drop_columns(column):\n",
        "    global df\n",
        "    if column in df.columns:\n",
        "        df.drop(column, axis=1, inplace=True)\n",
        "        display_data(f\"Column '{column}' dropped successfully.\")\n",
        "    else:\n",
        "        display_data(f\"Column '{column}' not found.\")\n",
        "\n",
        "\n",
        "def drop_na():\n",
        "    global df\n",
        "    df.dropna(inplace=True)\n",
        "    display_data(\"Nans dropped successfully.\")\n",
        "\n",
        "def simple_imputer(strategy):\n",
        "    global df\n",
        "    numerical_cols = df.select_dtypes(exclude='object').columns\n",
        "    imputer = SimpleImputer(missing_values=np.nan, strategy=strategy).fit(df[numerical_cols])\n",
        "    df[numerical_cols] = imputer.transform(df[numerical_cols])\n",
        "    display_data(\"Data imputed successfully.\")\n",
        "\n",
        "\n",
        "def label_encoder(column):\n",
        "    global df\n",
        "    if df[column].dtype == \"object\":\n",
        "            encoder = LabelEncoder()\n",
        "            df[column] = encoder.fit_transform(df[column])\n",
        "            display_data(\"Data encoded successfully.\")\n",
        "    else:\n",
        "        display_data(\"column must be an object datatype.\")\n",
        "\n",
        "\n",
        "\n",
        "def one_encoder(column):\n",
        "    global df\n",
        "    if df[column].dtype == \"object\":\n",
        "        encoder = OneHotEncoder()\n",
        "        encoded_data = encoder.fit_transform(df[[column]])\n",
        "        # Convert sparse matrix to DataFrame\n",
        "        encoded_df = pd.DataFrame(encoded_data.toarray(), columns=encoder.get_feature_names_out([column]))\n",
        "        # Concatenate the encoded DataFrame with the original DataFrame\n",
        "        df = pd.concat([df, encoded_df], axis=1)\n",
        "        df.drop(column, axis=1, inplace=True)\n",
        "        display_data(\"Data encoded successfully.\")\n",
        "    else:\n",
        "        display_data(\"column must be an object datatype.\")\n",
        "\n",
        "\n",
        "\n",
        "def scaler():\n",
        "    global df\n",
        "\n",
        "    # Identify the target column by its data type\n",
        "    target_column = df.select_dtypes(include=['object', 'category', 'int64', 'int', \"string\"]).columns[0:]\n",
        "\n",
        "    if len(target_column) == 0:\n",
        "        # If no target column, scale the entire DataFrame\n",
        "        scaler = StandardScaler()\n",
        "        scaled = scaler.fit_transform(df)\n",
        "        df_scaled = pd.DataFrame(scaled, columns=df.columns)\n",
        "        df = df_scaled\n",
        "    else:\n",
        "        target_column = df.select_dtypes(include=['object', 'category', 'int64', 'int', \"string\"]).columns[0]\n",
        "        # Separate features and target\n",
        "        X = df.drop(columns=[target_column])\n",
        "        y = df[target_column]\n",
        "\n",
        "        # Scale features\n",
        "        scaler = StandardScaler()\n",
        "        X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "        # Create a new dataframe with scaled features and the target column\n",
        "        df_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "        df_scaled[target_column] = y.values\n",
        "\n",
        "        # Update the global df\n",
        "        df = df_scaled\n",
        "\n",
        "    # Display a message\n",
        "    display_data(\"Data scaled successfully.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def min_max_scaler():\n",
        "    global df\n",
        "\n",
        "        # Identify the target column by its data type\n",
        "    target_column = df.select_dtypes(include=['object', 'category', 'int64', 'int', \"string\"]).columns[0:]\n",
        "\n",
        "    if len(target_column) == 0:\n",
        "            # If no target column, scale the entire DataFrame\n",
        "            scaler = MinMaxScaler()\n",
        "            scaled = scaler.fit_transform(df)\n",
        "            df_scaled = pd.DataFrame(scaled, columns=df.columns)\n",
        "            df = df_scaled\n",
        "    else:\n",
        "            target_column = df.select_dtypes(include=['object', 'category', 'int64', 'int', \"string\"]).columns[0]\n",
        "            # Separate features and target\n",
        "            X = df.drop(columns=[target_column])\n",
        "            y = df[target_column]\n",
        "\n",
        "            # Scale features\n",
        "            scaler = MinMaxScaler()\n",
        "            X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "            # Create a new dataframe with scaled features and the target column\n",
        "            df_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "            df_scaled[target_column] = y.values\n",
        "\n",
        "            # Update the global df\n",
        "            df = df_scaled\n",
        "\n",
        "\n",
        "    display_data(\"Data scaled successfully.\")\n",
        "\n",
        "\n",
        "\n",
        "# Converting the data into a DataFrame\n",
        "\n",
        "def apply_pca(n):\n",
        "    global df\n",
        "    n=int(n)\n",
        "    pca = PCA(n_components=n)\n",
        "    target_column = df.select_dtypes(include=['object', 'category', 'int64', \"int\"]).columns[0]\n",
        "    X = df.drop(columns=[target_column])\n",
        "    y = df[target_column]\n",
        "    principal_components = pca.fit_transform(X)\n",
        "\n",
        "    # Create a DataFrame with the principal components\n",
        "    pc_df = pd.DataFrame(data=principal_components, columns=[f'PC{i+1}' for i in range(n)])\n",
        "    pc_df[target_column] = y\n",
        "    df = pc_df\n",
        "    display_data(\"Data transformed successfully.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def ApplyOverSampling():\n",
        "    global df\n",
        "    target_column = df.select_dtypes(include=['object', 'category', 'int64', 'int', \"string\"]).columns[0]\n",
        "    # Separate features and target\n",
        "    X = df.drop(columns=[target_column])\n",
        "    y = df[target_column]\n",
        "    smote=SMOTE()\n",
        "    x_new,y_new=smote.fit_resample(X,y)\n",
        "    df = pd.concat([x_new,y_new],axis=1)\n",
        "    display_data(\"data transforme succesfully\")\n",
        "\n",
        "def ApplyUnderSampling():\n",
        "    global df\n",
        "    rus=RandomUnderSampler()\n",
        "    target_column = df.select_dtypes(include=['object', 'category', 'int64', 'int', \"string\"]).columns[0]\n",
        "    # Separate features and target\n",
        "    X = df.drop(columns=[target_column])\n",
        "    y = df[target_column]\n",
        "    x_new,y_new=rus.fit_resample(X,y) \n",
        "    df = pd.concat([x_new,y_new],axis=1)\n",
        "    display_data(\"data transforme succesfully\")\n",
        "                   \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ApplySelectPercentile(percentile, score_func=f_classif):\n",
        "    global df\n",
        "    target_column = df.select_dtypes(include=['object', 'category', 'int64', 'int', \"string\"]).columns[0]\n",
        "    X = df.drop(columns=[target_column])\n",
        "    y = df[target_column]\n",
        "    selector = SelectPercentile(score_func=score_func, percentile=percentile)\n",
        "    x_new = selector.fit_transform(X, y)\n",
        "    selected_columns = df.columns[:-1][selector.get_support()]\n",
        "    x_new_df = pd.DataFrame(x_new, columns=selected_columns)\n",
        "    df = pd.concat([x_new_df, pd.DataFrame(y)], axis=1)\n",
        "    display(\"data transformed succsesfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUkxhBnIxUTe"
      },
      "source": [
        "## Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3_vQfnw1xUTe"
      },
      "outputs": [],
      "source": [
        "def split_data():\n",
        "    global df, target_column\n",
        "    X = df.drop(target_column, axis=1)\n",
        "    y = df[target_column]\n",
        "    return X, y\n",
        "\n",
        "def logistic_regression():\n",
        "    global df, target_column\n",
        "    if target_column is None:\n",
        "        display_data(\"Target column not set.\")\n",
        "        return\n",
        "    X, y = split_data()\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "    lr = LogisticRegression(max_iter=1000)\n",
        "    lr.fit(X_train, y_train)\n",
        "    y_pred = lr.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    class_report = classification_report(y_test, y_pred)\n",
        "    result = f\"Accuracy: {accuracy}\\n\\nConfusion Matrix:\\n{conf_matrix}\\n\\nClassification Report:\\n{class_report}\"\n",
        "    display_data(result)\n",
        "\n",
        "def Random_forest():\n",
        "    global df, target_column\n",
        "    if target_column is None:\n",
        "        display_data(\"Target column not set.\")\n",
        "        return\n",
        "    X, y = split_data()\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    lr = RandomForestClassifier()\n",
        "    lr.fit(X_train, y_train)\n",
        "    y_pred = lr.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    class_report = classification_report(y_test, y_pred)\n",
        "    result = f\"Accuracy: {accuracy}\\n\\nConfusion Matrix:\\n{conf_matrix}\\n\\nClassification Report:\\n{class_report}\"\n",
        "    display_data(result)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def SVM():\n",
        "    global df, target_column\n",
        "    if target_column is None:\n",
        "        display_data(\"Target column not set.\")\n",
        "        return\n",
        "    X, y = split_data()\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    lr = SVC()\n",
        "    lr.fit(X_train, y_train)\n",
        "    y_pred = lr.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    class_report = classification_report(y_test, y_pred)\n",
        "    result = f\"Accuracy: {accuracy}\\n\\nConfusion Matrix:\\n{conf_matrix}\\n\\nClassification Report:\\n{class_report}\"\n",
        "    display_data(result)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxnmEk2fxUTf"
      },
      "source": [
        "# Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rWoAaIWexUTf"
      },
      "outputs": [],
      "source": [
        "def split_data_regression():\n",
        "    global df, target_column_regression\n",
        "    X = df.drop(target_column_regression, axis=1)\n",
        "    y = df[target_column_regression]\n",
        "    return X, y\n",
        "\n",
        "\n",
        "\n",
        "def linear_regression():\n",
        "    global df, target_column_regression\n",
        "    if target_column_regression is None:\n",
        "        display_data(\"Target column not set.\")\n",
        "        return\n",
        "    X, y = split_data_regression()\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "    lr = LinearRegression()\n",
        "    lr.fit(X_train, y_train)\n",
        "    y_pred = lr.predict(X_test)\n",
        "    error = mean_squared_error(y_test, y_pred)\n",
        "    result = f\"Mean Squared Error: {error:.2f}\"\n",
        "    display_data(result)\n",
        "\n",
        "\n",
        "\n",
        "def S_V_R():\n",
        "    global df, target_column_regression\n",
        "\n",
        "    if target_column_regression is None:\n",
        "        display_data(\"Target column not set.\")\n",
        "        return\n",
        "\n",
        "    X, y = split_data_regression()\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    svr = SVR()\n",
        "\n",
        "    svr.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "    y_pred = svr.predict(X_test)\n",
        "\n",
        "    error = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "    result = f\"Mean Squared Error: {error:.2f}\"\n",
        "\n",
        "    display_data(result)\n",
        "\n",
        "\n",
        "\n",
        "def random_forest_regression():\n",
        "    global df, target_column_regression\n",
        "\n",
        "\n",
        "    if target_column_regression is None:\n",
        "        display_data(\"Target column not set.\")\n",
        "        return\n",
        "\n",
        "\n",
        "    X, y = split_data_regression()\n",
        "\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "    lr = RandomForestRegressor()\n",
        "\n",
        "\n",
        "    lr.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = lr.predict(X_test)\n",
        "    error = mean_squared_error(y_test, y_pred)\n",
        "    result = f\"Mean Squared Error: {error:.2f}\"\n",
        "    display_data(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nw8QgnqkxUTf"
      },
      "source": [
        "## Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lSJR7oK8xUTg"
      },
      "outputs": [],
      "source": [
        "def clustering(n):\n",
        "    global df\n",
        "    kmeans = KMeans(n_clusters=n, init='k-means++', random_state=42)\n",
        "    y_kmeans = kmeans.fit_predict(df)\n",
        "    df['Cluster'] = y_kmeans\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5pMFwlrxUTg"
      },
      "source": [
        "## GUI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-SWJICKOxUTg"
      },
      "outputs": [],
      "source": [
        "def execute_selected_function(selected_option):\n",
        "    try:\n",
        "        if selected_option == \"head_of_data\":\n",
        "            result = head_of_data()\n",
        "        elif selected_option == \"tail_of_data\":\n",
        "            result = tail_of_data()\n",
        "        elif selected_option == \"info_about_data\":\n",
        "            result = info_about_data()\n",
        "        elif selected_option == \"describe_data\":\n",
        "            result = describe_data()\n",
        "        elif selected_option == \"shape_of_data\":\n",
        "            result = shape_of_data()\n",
        "        elif selected_option == \"columns_of_data\":\n",
        "            result = columns_of_data()\n",
        "        elif selected_option == \"nans_in_data\":\n",
        "            result = nans_in_data()\n",
        "        elif selected_option == \"drop_columns\":\n",
        "            get_column_name()\n",
        "            return\n",
        "        elif selected_option == \"drop_na\":\n",
        "            drop_na()\n",
        "            return\n",
        "        elif selected_option == \"simple_imputer\":\n",
        "            get_strategy()\n",
        "        elif selected_option == \"label_encoder\":\n",
        "            get_column_to_encode()\n",
        "        elif selected_option == \"one_encoder\":\n",
        "            get_column_to_encode_one()\n",
        "        elif selected_option == \"scaler\":\n",
        "            scaler()\n",
        "            return\n",
        "        elif selected_option == \"min_max_scaler\":\n",
        "            min_max_scaler()\n",
        "            return\n",
        "        elif selected_option == \"PCA\":\n",
        "            for_pca()\n",
        "            return\n",
        "        elif selected_option == \"Logistic Regression\":\n",
        "            logistic_regression()\n",
        "            return\n",
        "        elif selected_option == \"Random forest\":\n",
        "            Random_forest()\n",
        "            return\n",
        "\n",
        "        elif selected_option == \"SVM\":\n",
        "            SVM()\n",
        "            return\n",
        "        elif selected_option == \"Linear Regression\":\n",
        "            linear_regression()\n",
        "            return\n",
        "        elif selected_option == \"SVR\":\n",
        "            S_V_R()\n",
        "            return\n",
        "        elif selected_option == \"Random under sampling\":\n",
        "            ApplyUnderSampling()\n",
        "            return\n",
        "        elif selected_option == \"Random over sampling\":\n",
        "            ApplyOverSampling()\n",
        "            return\n",
        "        else:\n",
        "            result = \"Invalid option.\"\n",
        "\n",
        "        display_data(result)\n",
        "    except Exception as e:\n",
        "        display_data(\"Error: \" + str(e))\n",
        "\n",
        "def get_column_name():\n",
        "    column_window = Toplevel(root)\n",
        "    column_window.title(\"Enter Column Name\")\n",
        "\n",
        "    label = Label(column_window, text=\"Enter column name:\")\n",
        "    label.pack(pady=10)\n",
        "\n",
        "    entry = Entry(column_window)\n",
        "    entry.pack(pady=5)\n",
        "\n",
        "    def submit():\n",
        "        column_name = entry.get()\n",
        "        drop_columns(column_name)\n",
        "        column_window.destroy()\n",
        "\n",
        "    button = Button(column_window, text=\"Submit\", command=submit)\n",
        "    button.pack(pady=5)\n",
        "\n",
        "\n",
        "def get_strategy():\n",
        "    column_window = Toplevel(root)\n",
        "    column_window.title(\"Enter Strategy Name\")\n",
        "\n",
        "    label = Label(column_window, text=\"Enter Strategy name:\")\n",
        "    label.pack(pady=10)\n",
        "\n",
        "    entry = Entry(column_window)\n",
        "    entry.pack(pady=5)\n",
        "\n",
        "    def submit():\n",
        "        strategy_name = entry.get()\n",
        "        simple_imputer(strategy_name)\n",
        "        column_window.destroy()\n",
        "\n",
        "    button = Button(column_window, text=\"Submit\", command=submit)\n",
        "    button.pack(pady=5)\n",
        "\n",
        "\n",
        "def get_column_to_encode():\n",
        "    column_window = Toplevel(root)\n",
        "    column_window.title(\"Enter Column Name\")\n",
        "\n",
        "    label = Label(column_window, text=\"Enter Column Name\")\n",
        "    label.pack(pady=10)\n",
        "\n",
        "    entry = Entry(column_window)\n",
        "    entry.pack(pady=5)\n",
        "\n",
        "    def submit():\n",
        "        column_name = entry.get()\n",
        "        label_encoder(column_name)\n",
        "        column_window.destroy()\n",
        "\n",
        "    button = Button(column_window, text=\"Submit\", command=submit)\n",
        "    button.pack(pady=5)\n",
        "\n",
        "\n",
        "def get_column_to_encode_one():\n",
        "    column_window = Toplevel(root)\n",
        "    column_window.title(\"Enter Column Name\")\n",
        "\n",
        "    label = Label(column_window, text=\"Enter Column Name\")\n",
        "    label.pack(pady=10)\n",
        "\n",
        "    entry = Entry(column_window)\n",
        "    entry.pack(pady=5)\n",
        "\n",
        "    def submit():\n",
        "        column_name = entry.get()\n",
        "        one_encoder(column_name)\n",
        "        column_window.destroy()\n",
        "\n",
        "    button = Button(column_window, text=\"Submit\", command=submit)\n",
        "    button.pack(pady=5)\n",
        "\n",
        "\n",
        "def get_target_column():\n",
        "    column_window = Toplevel(root)\n",
        "    column_window.title(\"Enter Target Column Name\")\n",
        "\n",
        "    label = Label(column_window, text=\"Enter target column name:\")\n",
        "    label.pack(pady=10)\n",
        "\n",
        "    entry = Entry(column_window)\n",
        "    entry.pack(pady=5)\n",
        "\n",
        "    def submit():\n",
        "        global target_column\n",
        "        target_column = entry.get()\n",
        "        if target_column in df.columns:\n",
        "            display_data(f\"Target column '{target_column}' set successfully.\")\n",
        "            column_window.destroy()\n",
        "            Classification()\n",
        "        else:\n",
        "            display_data(f\"Target column '{target_column}' not found.\")\n",
        "\n",
        "    submit_button = Button(column_window, text=\"Submit\", command=submit)\n",
        "    submit_button.pack(pady=10)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_target_column_regression():\n",
        "    column_window = Toplevel(root)\n",
        "    column_window.title(\"Enter Target Column Name for Regression\")\n",
        "\n",
        "    label = Label(column_window, text=\"Enter target column name:\")\n",
        "    label.pack(pady=10)\n",
        "\n",
        "    entry = Entry(column_window)\n",
        "    entry.pack(pady=5)\n",
        "\n",
        "    def submit():\n",
        "        global target_column_regression\n",
        "        target_column_regression = entry.get()\n",
        "        if target_column_regression in df.columns:\n",
        "            display_data(f\"Target column '{target_column_regression}' set successfully for Regression.\")\n",
        "            column_window.destroy()\n",
        "            Regression()\n",
        "        else:\n",
        "            display_data(f\"Target column '{target_column_regression}' not found.\")\n",
        "    submit_button = Button(column_window, text=\"Submit\", command=submit)\n",
        "    submit_button.pack(pady=10)\n",
        "\n",
        "\n",
        "def get_percent():\n",
        "    column_window = Toplevel(root)\n",
        "    column_window.title(\"Enter the percent\")\n",
        "\n",
        "    label = Label(column_window, text=\"Enter the percent\")\n",
        "    label.pack(pady=10)\n",
        "\n",
        "    entry = Entry(column_window)\n",
        "    entry.pack(pady=5)\n",
        "\n",
        "    def submit():\n",
        "        global percent\n",
        "        percent = entry.get()\n",
        "        percent = int(percent)\n",
        "        try:\n",
        "            if percent > 0:\n",
        "                display_data(f\"percent is '{percent}' set successfully.\")\n",
        "                column_window.destroy()\n",
        "                ApplySelectPercentile(percent)\n",
        "        except Exception as e:\n",
        "            display_data(\"Error: \" + str(e))\n",
        "\n",
        "    submit_button = Button(column_window, text=\"Submit\", command=submit)\n",
        "    submit_button.pack(pady=10)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_number_of_clusters():\n",
        "    column_window = Toplevel(root)\n",
        "    column_window.title(\"Enter Number of Clusters\")\n",
        "\n",
        "    label = Label(column_window, text=\"Enter number of clusters:\")\n",
        "    label.pack(pady=10)\n",
        "\n",
        "    entry = Entry(column_window)\n",
        "    entry.pack(pady=5)\n",
        "\n",
        "    def submit():\n",
        "        global num_clusters\n",
        "        num_clusters = entry.get()\n",
        "        num_clusters = int(num_clusters)\n",
        "        try:\n",
        "            if num_clusters > 0:\n",
        "                display_data(f\"Number of clusters '{num_clusters}' set successfully.\")\n",
        "                column_window.destroy()\n",
        "                clustering(num_clusters)\n",
        "            else:\n",
        "                display_data(\"Number of clusters must be a positive integer.\")\n",
        "        except Exception as e:\n",
        "            display_data(\"Error: \" + str(e))\n",
        "\n",
        "    submit_button = Button(column_window, text=\"Submit\", command=submit)\n",
        "    submit_button.pack(pady=10)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def for_pca():\n",
        "    column_window = Toplevel(root)\n",
        "    column_window.title(\"Enter The Number of Components\")\n",
        "\n",
        "    label = Label(column_window, text=\"Enter the number of components:\")\n",
        "    label.pack(pady=10)\n",
        "\n",
        "    entry = Entry(column_window)\n",
        "    entry.pack(pady=5)\n",
        "\n",
        "    def submit():\n",
        "        n = entry.get()\n",
        "        apply_pca(n)\n",
        "        column_window.destroy()\n",
        "\n",
        "    submit_button = Button(column_window, text=\"Submit\", command=submit)\n",
        "    submit_button.pack(pady=10)\n",
        "\n",
        "def Regression():\n",
        "    algorithms = [\n",
        "        \"Linear Regression\",\n",
        "        \"SVR\",\n",
        "        \"Random Forest Regressor\"\n",
        "    ]\n",
        "    options_window = Toplevel(root)\n",
        "    options_window.title(\"Options\")\n",
        "\n",
        "    listbox = Listbox(options_window)\n",
        "    listbox.pack(side=\"left\", fill=\"y\")\n",
        "\n",
        "    for option in algorithms:\n",
        "        listbox.insert(\"end\", option)\n",
        "\n",
        "    scrollbar = Scrollbar(options_window, orient=\"vertical\")\n",
        "    scrollbar.pack(side=\"right\", fill=\"y\")\n",
        "\n",
        "    listbox.config(yscrollcommand=scrollbar.set)\n",
        "    scrollbar.config(command=listbox.yview)\n",
        "\n",
        "    def on_select(event):\n",
        "        selected_index = listbox.curselection()\n",
        "        if selected_index:\n",
        "            selected_option = listbox.get(selected_index)\n",
        "            threading.Thread(target=execute_selected_function, args=(selected_option,)).start()\n",
        "            options_window.destroy()\n",
        "\n",
        "\n",
        "\n",
        "    listbox.bind(\"<<ListboxSelect>>\", on_select)\n",
        "def Classification():\n",
        "    algorithms = [\n",
        "        \"Logistic Regression\",\n",
        "        \"Random forest\",\n",
        "        \"SVM\",\n",
        "    ]\n",
        "    options_window = Toplevel(root)\n",
        "    options_window.title(\"Options\")\n",
        "\n",
        "    listbox = Listbox(options_window)\n",
        "    listbox.pack(side=\"left\", fill=\"y\")\n",
        "\n",
        "    for option in algorithms:\n",
        "        listbox.insert(\"end\", option)\n",
        "\n",
        "    scrollbar = Scrollbar(options_window, orient=\"vertical\")\n",
        "    scrollbar.pack(side=\"right\", fill=\"y\")\n",
        "\n",
        "    listbox.config(yscrollcommand=scrollbar.set)\n",
        "    scrollbar.config(command=listbox.yview)\n",
        "\n",
        "    def on_select(event):\n",
        "        selected_index = listbox.curselection()\n",
        "        if selected_index:\n",
        "            selected_option = listbox.get(selected_index)\n",
        "            threading.Thread(target=execute_selected_function, args=(selected_option,)).start()\n",
        "            options_window.destroy()\n",
        "\n",
        "    listbox.bind(\"<<ListboxSelect>>\", on_select)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Preprocessing():\n",
        "    function_names = [\n",
        "        \"head_of_data\",\n",
        "        \"tail_of_data\",\n",
        "        \"info_about_data\",\n",
        "        \"describe_data\",\n",
        "        \"shape_of_data\",\n",
        "        \"columns_of_data\",\n",
        "        \"nans_in_data\",\n",
        "        \"drop_columns\",\n",
        "        \"drop_na\",\n",
        "        \"simple_imputer\",\n",
        "        \"label_encoder\",\n",
        "        \"one_encoder\",\n",
        "        \"scaler\",\n",
        "        \"min_max_scaler\",\n",
        "        \"PCA\",\n",
        "        \"Random over sampling\",\n",
        "        \"Random under sampling\"\n",
        "    ]\n",
        "\n",
        "    options_window = Toplevel(root)\n",
        "    options_window.title(\"Options\")\n",
        "\n",
        "    listbox = Listbox(options_window)\n",
        "    listbox.pack(side=\"left\", fill=\"y\")\n",
        "\n",
        "    for option in function_names:\n",
        "        listbox.insert(\"end\", option)\n",
        "\n",
        "    scrollbar = Scrollbar(options_window, orient=\"vertical\")\n",
        "    scrollbar.pack(side=\"right\", fill=\"y\")\n",
        "\n",
        "    listbox.config(yscrollcommand=scrollbar.set)\n",
        "    scrollbar.config(command=listbox.yview)\n",
        "\n",
        "    def on_select(event):\n",
        "        selected_index = listbox.curselection()\n",
        "        if selected_index:\n",
        "            selected_option = listbox.get(selected_index)\n",
        "            threading.Thread(target=execute_selected_function, args=(selected_option,)).start()\n",
        "            options_window.destroy()\n",
        "\n",
        "    listbox.bind(\"<<ListboxSelect>>\", on_select)\n",
        "\n",
        "def display_data(data):\n",
        "    output_text.delete(1.0, \"end\")\n",
        "    output_text.insert(\"end\", data)\n",
        "\n",
        "root = Tk()\n",
        "root.title(\"Machine Learning Project\")\n",
        "\n",
        "browse_button = Button(root, text=\"Browse\", command=browse_file, font=(\"Arial\", 10, \"bold\"), foreground=\"#00FF00\",\n",
        "                       background=\"#000000\", activebackground=\"#00FF00\")\n",
        "browse_button.pack(pady=10)\n",
        "\n",
        "preprocess_button = Button(root, text=\"Preprocessing\", command=Preprocessing, font=(\"Arial\", 10, \"bold\"), foreground=\"#05313d\",\n",
        "                           background=\"#00ffff\", activebackground=\"#05313d\")\n",
        "preprocess_button.pack(padx=20, pady=10)\n",
        "\n",
        "target_button = Button(root, text=\"Classification\", command=get_target_column, font=(\"Arial\", 10, \"bold\"), foreground=\"#FF4500\",\n",
        "                       background=\"#000000\", activebackground=\"#FF4500\")\n",
        "Regression_button = Button(root,\n",
        "                          text=\"Regression\",\n",
        "                          command=get_target_column_regression,\n",
        "                          font=(\"Arial\", 10, \"bold\"),\n",
        "                          foreground=\"cyan\",\n",
        "                          background=\"#000000\",\n",
        "                          activebackground=\"cyan\")\n",
        "\n",
        "\n",
        "Clustering_button = Button(root,\n",
        "                          text=\"Clustering\",\n",
        "                          command=get_number_of_clusters,\n",
        "                          font=(\"Arial\", 10, \"bold\"),\n",
        "                          foreground=\"blue\",\n",
        "                          background=\"#000000\",\n",
        "                          activebackground=\"blue\")\n",
        "\n",
        "\n",
        "\n",
        "feature_button = Button(root,\n",
        "                          text=\"feature selection\",\n",
        "                          command=get_percent,\n",
        "                          font=(\"Arial\", 10, \"bold\"),\n",
        "                          foreground=\"blue\",\n",
        "                          background=\"#000000\",\n",
        "                          activebackground=\"blue\")\n",
        "\n",
        "Regression_button.pack(side=LEFT, padx=10)\n",
        "target_button.pack(side=LEFT, padx=30, pady=10)\n",
        "Clustering_button.pack(side=LEFT, padx=10)\n",
        "feature_button.pack(side=LEFT, padx=40, pady=10)\n",
        "output_text = Text(root, height=40, width=80)\n",
        "output_text.pack(pady=10)\n",
        "\n",
        "root.mainloop()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
